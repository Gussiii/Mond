{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37095f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35b11c7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.8\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d98ca7-a808-4afa-be21-124eb20879dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install plotly\n",
    "#!pip install Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b85b09",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23530515",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ps.options.display.max_rows = 10\n",
    "\n",
    "ps.set_option('plotting.backend', 'plotly')\n",
    "\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"] = \"lab\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df841052",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyspark version: 3.3.1\n"
     ]
    }
   ],
   "source": [
    "print(f'pyspark version: {pyspark.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d082138d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Spark Secion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc05ea19",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf()\n",
    "\n",
    "conf.setAppName('Task1')\n",
    "conf.setMaster('local[2]')\n",
    "\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6655ac0-59d4-41a7-bc97-555daa749e0e",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1765190a-2a29-4af6-b036-63e0b7aecfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Price Discount (%)</th>\n",
       "      <th>In-Store Promo</th>\n",
       "      <th>Catalogue Promo</th>\n",
       "      <th>Store End Promo</th>\n",
       "      <th>Google_Mobility</th>\n",
       "      <th>Covid_Flag</th>\n",
       "      <th>V_DAY</th>\n",
       "      <th>EASTER</th>\n",
       "      <th>CHRISTMAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKU1</td>\n",
       "      <td>05/02/17</td>\n",
       "      <td>27750</td>\n",
       "      <td>0%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKU1</td>\n",
       "      <td>12/02/17</td>\n",
       "      <td>29023</td>\n",
       "      <td>0%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SKU1</td>\n",
       "      <td>19/02/17</td>\n",
       "      <td>45630</td>\n",
       "      <td>17%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKU1</td>\n",
       "      <td>26/02/17</td>\n",
       "      <td>26789</td>\n",
       "      <td>0%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKU1</td>\n",
       "      <td>05/03/17</td>\n",
       "      <td>41999</td>\n",
       "      <td>17%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product      date  Sales Price Discount (%)  In-Store Promo  Catalogue Promo  Store End Promo  Google_Mobility  Covid_Flag  V_DAY  EASTER  CHRISTMAS\n",
       "0    SKU1  05/02/17  27750                 0%               0                0                0              0.0           0      0       0          0\n",
       "1    SKU1  12/02/17  29023                 0%               1                0                1              0.0           0      1       0          0\n",
       "2    SKU1  19/02/17  45630                17%               0                0                0              0.0           0      0       0          0\n",
       "3    SKU1  26/02/17  26789                 0%               1                0                1              0.0           0      0       0          0\n",
       "4    SKU1  05/03/17  41999                17%               0                0                0              0.0           0      0       0          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd = os.getcwd()\n",
    "path_data = os.path.join(wd, 'study_case/Task1/data/', 'forcasting_cs_data.csv')\n",
    "#path_data = os.path.join(wd, 'data', 'forcasting_cs_data.csv')\n",
    "df = ps.read_csv(path_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716248cf-00e5-4835-897d-49db14704889",
   "metadata": {},
   "source": [
    "## Column name homogenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4971f38f-6b7d-4464-9547-689780b45e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [re.sub(\"[^A-Z0-9 ]\", \"\", column, 0, re.IGNORECASE) for column in df.columns]\n",
    "columns = [column.lower().replace(' ','') for column in columns]\n",
    "# columns = ['product',\n",
    "#             'date',\n",
    "#             'sales',\n",
    "#             'price_discount',\n",
    "#             'instore_promo',\n",
    "#             'catalogue_promo',\n",
    "#             'store_end_promo',\n",
    "#             'google_mobility',\n",
    "#             'covid_flag',\n",
    "#             'v_day',\n",
    "#             'easter',\n",
    "#             'christmas']\n",
    "df.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e5c77-c73a-4f2c-ada0-1e584b949b5d",
   "metadata": {},
   "source": [
    "## Type convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a57ad6b-bcb0-4ea1-8613-a003257ef6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = ps.to_datetime(df['date'], infer_datetime_format=True)\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['cw'] = df['date'].dt.week\n",
    "df['quarter'] = df['date'].dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sku_number'] = df['product'].apply(lambda x: int(x.replace('SKU','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['product'], axis= 1)\n",
    "df['pricediscount'] = df['pricediscount'].apply(lambda x: float(x.replace('%','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b92dfb58-a9c2-4999-a092-cf88bb70d9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1218, 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, sum, max, col, concat, lit\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "        StructField('sku_number', IntegerType()),\n",
    "        StructField('ds', TimestampType()),\n",
    "        StructField('yhat', DoubleType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def apply_model(df):\n",
    "\n",
    "    def train_fitted_prophet(df, cutoff):\n",
    "\n",
    "        ts_train = (df\n",
    "                    .query('date <= @cutoff')\n",
    "                    .rename(columns={'date': 'ds', 'sales': 'y'})\n",
    "                    .sort_values('ds')\n",
    "                    \n",
    "                    )\n",
    "\n",
    "        ts_test = (df\n",
    "                   .query('date > @cutoff')\n",
    "                   .rename(columns={'date': 'ds', 'sales': 'y'})\n",
    "                   .sort_values('ds')\n",
    "                   .assign(ds=lambda x: pd.to_datetime(x[\"ds\"]))\n",
    "                   .drop('y', axis=1)\n",
    "                   )\n",
    "                       \n",
    "        # init model\n",
    "        m = Prophet(\n",
    "                    interval_width=0.95,\n",
    "                    growth='linear',\n",
    "                    daily_seasonality=False,\n",
    "                    weekly_seasonality=True,\n",
    "                    yearly_seasonality=True,\n",
    "                    seasonality_mode='multiplicative'\n",
    "        )\n",
    "\n",
    "        m.fit(ts_train)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "        ts_hat = (m.predict(ts_test)[[\"ds\", \"yhat\"]]\n",
    "                  .assign(ds=lambda x: pd.to_datetime(x[\"ds\"]))\n",
    "                  ).merge(ts_test, on=[\"ds\"], how=\"left\") \n",
    "        \n",
    "    \n",
    "        return pd.DataFrame(ts_hat, columns=schema.fieldNames())\n",
    "\n",
    "    return train_fitted_prophet(df, cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+------------------+\n",
      "|sku_number|                 ds|              yhat|\n",
      "+----------+-------------------+------------------+\n",
      "|         1|2020-11-10 00:00:00|  67117.2669579449|\n",
      "|         1|2020-11-15 00:00:00| 64084.62953223526|\n",
      "|         1|2020-11-22 00:00:00| 49089.69413483643|\n",
      "|         1|2020-11-29 00:00:00| 39004.15243287487|\n",
      "|         1|2020-12-01 00:00:00| 41404.33223606509|\n",
      "|         1|2020-12-04 00:00:00| 39212.15997928289|\n",
      "|         1|2020-12-07 00:00:00|62789.974895373096|\n",
      "|         1|2020-12-13 00:00:00|  97524.3986542807|\n",
      "|         1|2020-12-20 00:00:00|134349.01881582264|\n",
      "|         1|2020-12-27 00:00:00|135007.10244620257|\n",
      "|         2|2020-11-10 00:00:00|  7903.30488684252|\n",
      "|         2|2020-11-15 00:00:00| 7788.260524640101|\n",
      "|         2|2020-11-22 00:00:00| 8640.636494637607|\n",
      "|         2|2020-11-29 00:00:00| 9710.717418670001|\n",
      "|         2|2020-12-01 00:00:00| 9614.602956120474|\n",
      "|         2|2020-12-04 00:00:00|  8792.18266724299|\n",
      "|         2|2020-12-07 00:00:00| 6713.464919588251|\n",
      "|         2|2020-12-13 00:00:00| 6891.183017248942|\n",
      "|         2|2020-12-20 00:00:00|3791.0358369510805|\n",
      "|         2|2020-12-27 00:00:00| 1963.939298672672|\n",
      "+----------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "days_to_subtract = 60\n",
    "cutoff = df['date'].max() - timedelta(days=days_to_subtract)\n",
    "\n",
    "global_predictions = (df.to_spark()\n",
    "                        .groupBy(\"sku_number\")\n",
    "                        .apply(apply_model)\n",
    "                        )\n",
    "                        \n",
    "global_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
