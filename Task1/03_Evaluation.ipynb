{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37095f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35b11c7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.8\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d98ca7-a808-4afa-be21-124eb20879dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (5.11.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly) (8.1.0)\n",
      "Requirement already satisfied: Prophet in /opt/conda/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: LunarCalendar>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from Prophet) (0.0.9)\n",
      "Requirement already satisfied: convertdate>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Prophet) (2.4.0)\n",
      "Requirement already satisfied: setuptools>=42 in /opt/conda/lib/python3.10/site-packages (from Prophet) (65.5.1)\n",
      "Requirement already satisfied: wheel>=0.37.0 in /opt/conda/lib/python3.10/site-packages (from Prophet) (0.38.4)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in /opt/conda/lib/python3.10/site-packages (from Prophet) (1.0.8)\n",
      "Requirement already satisfied: setuptools-git>=1.2 in /opt/conda/lib/python3.10/site-packages (from Prophet) (1.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.10/site-packages (from Prophet) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.0.4 in /opt/conda/lib/python3.10/site-packages (from Prophet) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from Prophet) (3.6.2)\n",
      "Requirement already satisfied: holidays>=0.14.2 in /opt/conda/lib/python3.10/site-packages (from Prophet) (0.17.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from Prophet) (2.8.2)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/conda/lib/python3.10/site-packages (from Prophet) (4.64.1)\n",
      "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /opt/conda/lib/python3.10/site-packages (from convertdate>=2.1.2->Prophet) (0.5.11)\n",
      "Requirement already satisfied: korean-lunar-calendar in /opt/conda/lib/python3.10/site-packages (from holidays>=0.14.2->Prophet) (0.3.1)\n",
      "Requirement already satisfied: hijri-converter in /opt/conda/lib/python3.10/site-packages (from holidays>=0.14.2->Prophet) (2.2.4)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from LunarCalendar>=0.0.9->Prophet) (2022.6)\n",
      "Requirement already satisfied: ephem>=3.7.5.3 in /opt/conda/lib/python3.10/site-packages (from LunarCalendar>=0.0.9->Prophet) (4.1.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->Prophet) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->Prophet) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->Prophet) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->Prophet) (21.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->Prophet) (1.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->Prophet) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.0.0->Prophet) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.0->Prophet) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly\n",
    "!pip install Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b85b09",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23530515",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ps.options.display.max_rows = 20\n",
    "\n",
    "ps.set_option('plotting.backend', 'plotly')\n",
    "\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"] = \"lab\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df841052",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyspark version: 3.3.1\n"
     ]
    }
   ],
   "source": [
    "print(f'pyspark version: {pyspark.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d082138d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Spark Secion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc05ea19",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf()\n",
    "\n",
    "conf.setAppName('Task1')\n",
    "conf.setMaster('local[2]')\n",
    "\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6655ac0-59d4-41a7-bc97-555daa749e0e",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1765190a-2a29-4af6-b036-63e0b7aecfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Price Discount (%)</th>\n",
       "      <th>In-Store Promo</th>\n",
       "      <th>Catalogue Promo</th>\n",
       "      <th>Store End Promo</th>\n",
       "      <th>Google_Mobility</th>\n",
       "      <th>Covid_Flag</th>\n",
       "      <th>V_DAY</th>\n",
       "      <th>EASTER</th>\n",
       "      <th>CHRISTMAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKU1</td>\n",
       "      <td>05/02/17</td>\n",
       "      <td>27750</td>\n",
       "      <td>0%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKU1</td>\n",
       "      <td>12/02/17</td>\n",
       "      <td>29023</td>\n",
       "      <td>0%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SKU1</td>\n",
       "      <td>19/02/17</td>\n",
       "      <td>45630</td>\n",
       "      <td>17%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKU1</td>\n",
       "      <td>26/02/17</td>\n",
       "      <td>26789</td>\n",
       "      <td>0%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKU1</td>\n",
       "      <td>05/03/17</td>\n",
       "      <td>41999</td>\n",
       "      <td>17%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product      date  Sales Price Discount (%)  In-Store Promo  Catalogue Promo  Store End Promo  Google_Mobility  Covid_Flag  V_DAY  EASTER  CHRISTMAS\n",
       "0    SKU1  05/02/17  27750                 0%               0                0                0              0.0           0      0       0          0\n",
       "1    SKU1  12/02/17  29023                 0%               1                0                1              0.0           0      1       0          0\n",
       "2    SKU1  19/02/17  45630                17%               0                0                0              0.0           0      0       0          0\n",
       "3    SKU1  26/02/17  26789                 0%               1                0                1              0.0           0      0       0          0\n",
       "4    SKU1  05/03/17  41999                17%               0                0                0              0.0           0      0       0          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd = os.getcwd()\n",
    "path_data = os.path.join(wd, 'study_case/Task1/data/', 'forcasting_cs_data.csv')\n",
    "#path_data = os.path.join(wd, 'data', 'forcasting_cs_data.csv')\n",
    "df = ps.read_csv(path_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716248cf-00e5-4835-897d-49db14704889",
   "metadata": {},
   "source": [
    "## Column name homogenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4971f38f-6b7d-4464-9547-689780b45e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [re.sub(\"[^A-Z0-9 _]\", \"\", column, 0, re.IGNORECASE) for column in df.columns]\n",
    "columns = [column.replace('_',' ').title().replace(' ','') for column in columns]\n",
    "df.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e5c77-c73a-4f2c-ada0-1e584b949b5d",
   "metadata": {},
   "source": [
    "## Type convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Day'] = df['Date'].apply(lambda x: x.split('/')[0])\n",
    "df['Month'] = df['Date'].apply(lambda x: x.split('/')[1])\n",
    "df['Year'] = df['Date'].apply(lambda x: x.split('/')[2])\n",
    "df['Date'] = df['Month'] + '/' + df['Day'] + '/' + df['Year']\n",
    "df['Date'] = ps.to_datetime(df['Date'])\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Cw'] = df['Date'].dt.week\n",
    "df['Quarter'] = df['Date'].dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SkuNumber'] = df['Product'].apply(lambda x: int(x.replace('SKU','')))\n",
    "df = df.drop(['Product'], axis= 1)\n",
    "df['PriceDiscount'] = df['PriceDiscount'].apply(lambda x: float(x.replace('%','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b92dfb58-a9c2-4999-a092-cf88bb70d9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1218, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, sum, max, col, concat, lit\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema of the modle output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "        StructField('SkuNumber', IntegerType()),\n",
    "        StructField('ds', TimestampType()),\n",
    "        StructField('yhat', DoubleType()),\n",
    "        StructField('eval', StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PD UDF for training modles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet modle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def apply_prophet_model(df):\n",
    "\n",
    "    def modle_evaluate(df, cutoff, pred_df):\n",
    "            y = (df\n",
    "                   .query('Date > @cutoff')\n",
    "                   .rename(columns={'Date': 'ds', 'Sales': 'y'})\n",
    "                   .sort_values('ds')\n",
    "                   .assign(ds=lambda x: pd.to_datetime(x[\"ds\"]))\n",
    "                   .eval('y')\n",
    "                   )\n",
    "            \n",
    "            y_hat = pred_df['yhat'].values\n",
    "            return  pd.DataFrame(['{:0.3e}'.format(mean_absolute_percentage_error(y, y_hat))], columns=['Eval'])\n",
    "\n",
    "    def train_fitted_prophet(df, cutoff):\n",
    "\n",
    "        data_train = (df\n",
    "                    .query('Date <= @cutoff')\n",
    "                    .rename(columns={'Date': 'ds', 'Sales': 'y'})\n",
    "                    .sort_values('ds')\n",
    "                    )\n",
    "\n",
    "        data_test = (df\n",
    "                .query('Date > @cutoff')\n",
    "                   .rename(columns={'Date': 'ds', 'Sales': 'y'})\n",
    "                   .sort_values('ds')\n",
    "                   .assign(ds=lambda x: pd.to_datetime(x[\"ds\"]))\n",
    "                   .drop('y', axis=1)\n",
    "                   )\n",
    "                \n",
    "        # init model\n",
    "        model = Prophet(\n",
    "                    interval_width=0.95,\n",
    "                    growth='linear',\n",
    "                    daily_seasonality=False,\n",
    "                    weekly_seasonality=True,\n",
    "                    yearly_seasonality=True,\n",
    "                    seasonality_mode='multiplicative'\n",
    "        )\n",
    "\n",
    "        model.fit(data_train)\n",
    "\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "        y_hat = (model.predict(data_test)[[\"ds\", \"yhat\"]]\n",
    "            .assign(ds=lambda x: pd.to_datetime(x[\"ds\"]))).merge(data_test, on=[\"ds\"], how=\"left\")\n",
    "            \n",
    "        pred_df = pd.DataFrame(y_hat, columns=schema.fieldNames())\n",
    "\n",
    "        y_hat['eval'] = modle_evaluate(df, cutoff, pred_df)\n",
    "\n",
    "        return pd.DataFrame(y_hat, columns=schema.fieldNames())\n",
    "\n",
    "    return train_fitted_prophet(df, cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|SkuNumber|     eval|\n",
      "+---------+---------+\n",
      "|        1|2.099e+20|\n",
      "|        2|8.688e+18|\n",
      "|        3|8.033e+19|\n",
      "|        4|2.418e+19|\n",
      "|        5|2.661e+19|\n",
      "|        6|3.056e-01|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "days_to_subtract = 90\n",
    "cutoff = df['Date'].max() - timedelta(days=days_to_subtract)\n",
    "\n",
    "prophet_predictions = (df.to_spark()\n",
    "                        .groupBy(\"SkuNumber\")\n",
    "                        .apply(apply_prophet_model))\n",
    "                        \n",
    "prophet_predictions.filter(col(\"eval\").isNotNull()).select(col(\"SkuNumber\"), col(\"eval\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
